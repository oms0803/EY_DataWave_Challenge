{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EY Datawave Challenge Code\n",
    "\n",
    "**Simple rule**: \n",
    "- all \"df_xx\" types are pd.DataFrame\n",
    "- \"xx_data\" are usually NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import normalize\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cool point got from here\n",
    "\n",
    "https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fix random seed for reproducibility\n",
    "# seed = 7\n",
    "# np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('acc') >= 0.9:\n",
    "            print(\"Reached 90% acc so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "reach_90acc = MyCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric for F1\n",
    "\n",
    "https://medium.com/@thongonary/how-to-compute-f1-score-for-each-epoch-in-keras-a1acd17715a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1(keras.callbacks.Callback):\n",
    "    def __init__(self, val_data):\n",
    "        super().__init__()\n",
    "        self.validation_data = val_data\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict)\n",
    "        _val_recall = recall_score(val_targ, val_predict)\n",
    "        _val_precision = precision_score(val_targ, val_predict)\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print (\"— val_f1: %f — val_precision: %f — val_recall %f\" %(_val_f1, _val_precision, _val_recall))\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the training Data\n",
    "\n",
    "df is training data + label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read training data\n",
    "df_train = pd.read_csv(\"/Users/Godwithus/Desktop/EY/data_train.csv\", low_memory=False) #nrows = integer\n",
    "df_train = df_train.loc[:,'hash':'y_exit']\n",
    "df_train.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the test Data\n",
    "\n",
    "df_test is test data + label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read test data\n",
    "df_test = pd.read_csv(\"/Users/Godwithus/Desktop/EY/data_test.csv\", low_memory=False)\n",
    "df_test = df_test.loc[:,'hash':'y_exit']\n",
    "df_test.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pred and Eval\n",
    "\n",
    "First, change the time variables into pd.timedelta.\n",
    "\n",
    "Then, divide the df_test into 2 subparts:\n",
    "\n",
    "1. df_test_eval: Used for evaluating test accuracy (where x_exit value exists)\n",
    "2. df_test_pred: the data we want to predict from (where x_exit value do not exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the test data into pred and eval\n",
    "df_test['time_entry']=pd.to_timedelta(df_test['time_entry'])\n",
    "df_test['time_exit']=pd.to_timedelta(df_test['time_exit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 814262 entries, 0 to 814261\n",
      "Data columns (total 11 columns):\n",
      "hash             814262 non-null object\n",
      "trajectory_id    814262 non-null object\n",
      "time_entry       814262 non-null object\n",
      "time_exit        814262 non-null object\n",
      "vmax             814262 non-null object\n",
      "vmin             814262 non-null object\n",
      "vmean            814262 non-null object\n",
      "x_entry          814262 non-null float64\n",
      "y_entry          814262 non-null float64\n",
      "x_exit           814262 non-null float64\n",
      "y_exit           814262 non-null float64\n",
      "dtypes: float64(4), object(7)\n",
      "memory usage: 68.3+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 202937 entries, 0 to 202936\n",
      "Data columns (total 11 columns):\n",
      "hash             202937 non-null object\n",
      "trajectory_id    202937 non-null object\n",
      "time_entry       202937 non-null timedelta64[ns]\n",
      "time_exit        202937 non-null timedelta64[ns]\n",
      "vmax             202937 non-null object\n",
      "vmin             202937 non-null object\n",
      "vmean            202937 non-null object\n",
      "x_entry          202937 non-null float64\n",
      "y_entry          202937 non-null float64\n",
      "x_exit           202937 non-null object\n",
      "y_exit           202937 non-null object\n",
      "dtypes: float64(2), object(7), timedelta64[ns](2)\n",
      "memory usage: 17.0+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>trajectory_id</th>\n",
       "      <th>time_entry</th>\n",
       "      <th>time_exit</th>\n",
       "      <th>vmax</th>\n",
       "      <th>vmin</th>\n",
       "      <th>vmean</th>\n",
       "      <th>x_entry</th>\n",
       "      <th>y_entry</th>\n",
       "      <th>x_exit</th>\n",
       "      <th>y_exit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000a8602cf2def930488dee7cdad104_1</td>\n",
       "      <td>traj_0000a8602cf2def930488dee7cdad104_1_0</td>\n",
       "      <td>07:04:31</td>\n",
       "      <td>07:08:32</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.751014e+06</td>\n",
       "      <td>-1.909398e+07</td>\n",
       "      <td>3.750326e+06</td>\n",
       "      <td>-1.913634e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000a8602cf2def930488dee7cdad104_1</td>\n",
       "      <td>traj_0000a8602cf2def930488dee7cdad104_1_1</td>\n",
       "      <td>07:20:34</td>\n",
       "      <td>07:25:42</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.743937e+06</td>\n",
       "      <td>-1.932247e+07</td>\n",
       "      <td>3.744975e+06</td>\n",
       "      <td>-1.931966e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000a8602cf2def930488dee7cdad104_1</td>\n",
       "      <td>traj_0000a8602cf2def930488dee7cdad104_1_2</td>\n",
       "      <td>07:53:32</td>\n",
       "      <td>08:03:25</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.744868e+06</td>\n",
       "      <td>-1.929356e+07</td>\n",
       "      <td>3.744816e+06</td>\n",
       "      <td>-1.929284e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000a8602cf2def930488dee7cdad104_1</td>\n",
       "      <td>traj_0000a8602cf2def930488dee7cdad104_1_3</td>\n",
       "      <td>08:17:50</td>\n",
       "      <td>08:37:23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.744880e+06</td>\n",
       "      <td>-1.929229e+07</td>\n",
       "      <td>3.744809e+06</td>\n",
       "      <td>-1.929049e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000a8602cf2def930488dee7cdad104_1</td>\n",
       "      <td>traj_0000a8602cf2def930488dee7cdad104_1_4</td>\n",
       "      <td>14:38:09</td>\n",
       "      <td>14:38:09</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.744909e+06</td>\n",
       "      <td>-1.928558e+07</td>\n",
       "      <td>3.744909e+06</td>\n",
       "      <td>-1.928558e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 hash  \\\n",
       "0  0000a8602cf2def930488dee7cdad104_1   \n",
       "1  0000a8602cf2def930488dee7cdad104_1   \n",
       "2  0000a8602cf2def930488dee7cdad104_1   \n",
       "3  0000a8602cf2def930488dee7cdad104_1   \n",
       "4  0000a8602cf2def930488dee7cdad104_1   \n",
       "\n",
       "                               trajectory_id time_entry time_exit vmax vmin  \\\n",
       "0  traj_0000a8602cf2def930488dee7cdad104_1_0   07:04:31  07:08:32             \n",
       "1  traj_0000a8602cf2def930488dee7cdad104_1_1   07:20:34  07:25:42             \n",
       "2  traj_0000a8602cf2def930488dee7cdad104_1_2   07:53:32  08:03:25             \n",
       "3  traj_0000a8602cf2def930488dee7cdad104_1_3   08:17:50  08:37:23             \n",
       "4  traj_0000a8602cf2def930488dee7cdad104_1_4   14:38:09  14:38:09             \n",
       "\n",
       "  vmean       x_entry       y_entry        x_exit        y_exit  \n",
       "0        3.751014e+06 -1.909398e+07  3.750326e+06 -1.913634e+07  \n",
       "1        3.743937e+06 -1.932247e+07  3.744975e+06 -1.931966e+07  \n",
       "2        3.744868e+06 -1.929356e+07  3.744816e+06 -1.929284e+07  \n",
       "3        3.744880e+06 -1.929229e+07  3.744809e+06 -1.929049e+07  \n",
       "4        3.744909e+06 -1.928558e+07  3.744909e+06 -1.928558e+07  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#debugging\n",
    "# print(df_test_pred)\n",
    "# print(df_test_eval)\n",
    "\n",
    "print (df_train.info())\n",
    "print (df_test.info())\n",
    "\n",
    "df_train.describe()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Training Data\n",
    "\n",
    "choose the features: \n",
    "\n",
    "*for rn, I cannot handle velocity since there are NaN.*\n",
    "\n",
    "Change the time values into float, by dividing into minutes.\n",
    "\n",
    "Finally, store train_data as NumPy arrays, and normalize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>trajectory_id</th>\n",
       "      <th>time_entry</th>\n",
       "      <th>time_exit</th>\n",
       "      <th>vmax</th>\n",
       "      <th>vmin</th>\n",
       "      <th>vmean</th>\n",
       "      <th>x_entry</th>\n",
       "      <th>y_entry</th>\n",
       "      <th>x_exit</th>\n",
       "      <th>y_exit</th>\n",
       "      <th>time_entry_seconds</th>\n",
       "      <th>time_exit_seconds</th>\n",
       "      <th>time_stayed_seconds</th>\n",
       "      <th>entry_inside</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000a8602cf2def930488dee7cdad104_1</td>\n",
       "      <td>traj_0000a8602cf2def930488dee7cdad104_1_0</td>\n",
       "      <td>07:04:31</td>\n",
       "      <td>07:08:32</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.751014e+06</td>\n",
       "      <td>-1.909398e+07</td>\n",
       "      <td>3.750326e+06</td>\n",
       "      <td>-1.913634e+07</td>\n",
       "      <td>25471.0</td>\n",
       "      <td>25712.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000a8602cf2def930488dee7cdad104_1</td>\n",
       "      <td>traj_0000a8602cf2def930488dee7cdad104_1_1</td>\n",
       "      <td>07:20:34</td>\n",
       "      <td>07:25:42</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.743937e+06</td>\n",
       "      <td>-1.932247e+07</td>\n",
       "      <td>3.744975e+06</td>\n",
       "      <td>-1.931966e+07</td>\n",
       "      <td>26434.0</td>\n",
       "      <td>26742.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000a8602cf2def930488dee7cdad104_1</td>\n",
       "      <td>traj_0000a8602cf2def930488dee7cdad104_1_2</td>\n",
       "      <td>07:53:32</td>\n",
       "      <td>08:03:25</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.744868e+06</td>\n",
       "      <td>-1.929356e+07</td>\n",
       "      <td>3.744816e+06</td>\n",
       "      <td>-1.929284e+07</td>\n",
       "      <td>28412.0</td>\n",
       "      <td>29005.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000a8602cf2def930488dee7cdad104_1</td>\n",
       "      <td>traj_0000a8602cf2def930488dee7cdad104_1_3</td>\n",
       "      <td>08:17:50</td>\n",
       "      <td>08:37:23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.744880e+06</td>\n",
       "      <td>-1.929229e+07</td>\n",
       "      <td>3.744809e+06</td>\n",
       "      <td>-1.929049e+07</td>\n",
       "      <td>29870.0</td>\n",
       "      <td>31043.0</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000a8602cf2def930488dee7cdad104_1</td>\n",
       "      <td>traj_0000a8602cf2def930488dee7cdad104_1_4</td>\n",
       "      <td>14:38:09</td>\n",
       "      <td>14:38:09</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.744909e+06</td>\n",
       "      <td>-1.928558e+07</td>\n",
       "      <td>3.744909e+06</td>\n",
       "      <td>-1.928558e+07</td>\n",
       "      <td>52689.0</td>\n",
       "      <td>52689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 hash  \\\n",
       "0  0000a8602cf2def930488dee7cdad104_1   \n",
       "1  0000a8602cf2def930488dee7cdad104_1   \n",
       "2  0000a8602cf2def930488dee7cdad104_1   \n",
       "3  0000a8602cf2def930488dee7cdad104_1   \n",
       "4  0000a8602cf2def930488dee7cdad104_1   \n",
       "\n",
       "                               trajectory_id time_entry time_exit vmax vmin  \\\n",
       "0  traj_0000a8602cf2def930488dee7cdad104_1_0   07:04:31  07:08:32             \n",
       "1  traj_0000a8602cf2def930488dee7cdad104_1_1   07:20:34  07:25:42             \n",
       "2  traj_0000a8602cf2def930488dee7cdad104_1_2   07:53:32  08:03:25             \n",
       "3  traj_0000a8602cf2def930488dee7cdad104_1_3   08:17:50  08:37:23             \n",
       "4  traj_0000a8602cf2def930488dee7cdad104_1_4   14:38:09  14:38:09             \n",
       "\n",
       "  vmean       x_entry       y_entry        x_exit        y_exit  \\\n",
       "0        3.751014e+06 -1.909398e+07  3.750326e+06 -1.913634e+07   \n",
       "1        3.743937e+06 -1.932247e+07  3.744975e+06 -1.931966e+07   \n",
       "2        3.744868e+06 -1.929356e+07  3.744816e+06 -1.929284e+07   \n",
       "3        3.744880e+06 -1.929229e+07  3.744809e+06 -1.929049e+07   \n",
       "4        3.744909e+06 -1.928558e+07  3.744909e+06 -1.928558e+07   \n",
       "\n",
       "   time_entry_seconds  time_exit_seconds  time_stayed_seconds  entry_inside  \n",
       "0             25471.0            25712.0                241.0             0  \n",
       "1             26434.0            26742.0                308.0             0  \n",
       "2             28412.0            29005.0                593.0             0  \n",
       "3             29870.0            31043.0               1173.0             0  \n",
       "4             52689.0            52689.0                  0.0             0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Prepare time stayed in the city hall (seconds)\n",
    "df_train['time_entry_seconds'] = pd.to_timedelta(df_train['time_entry']).dt.total_seconds()\n",
    "df_train['time_exit_seconds']=pd.to_timedelta(df_train['time_exit']).dt.total_seconds()\n",
    "df_train['time_stayed_seconds']=df_train['time_exit_seconds']-df_train['time_entry_seconds']\n",
    "\n",
    "df_train.head()\n",
    "\n",
    "# 2. prepare whether entry point is in cityhall\n",
    "x_in_city = (df_train['x_entry'] >=3750901.5068) & (df_train['x_entry']<=3770901.5068)\n",
    "y_in_city = (df_train['y_entry'] >= -19268905.6133) & (df_train['y_entry'] <= -19208905.6133)\n",
    "\n",
    "df_train['entry_inside'] = 1*(x_in_city & y_in_city)\n",
    "\n",
    "train_data=df_train.loc[:,['time_stayed_seconds','entry_inside']].values\n",
    "\n",
    "df_train.entry_inside.describe()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare Train Labels\n",
    "\n",
    "prepare the label for training:\n",
    "\n",
    "x_exit and y_exit values have to be within certain range. Do each of the comparison and store the value as 0 or 1 in train_label NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare training label\n",
    "\n",
    "target_x = (df_train['x_exit']>=3750901.5068) & (df_train['x_exit']<=3770901.5068)\n",
    "target_y = (df_train['y_exit']>=-19268905.6133) & (df_train['y_exit']<=-19208905.6133)\n",
    "\n",
    "train_label = 1*(target_x & target_y)\n",
    "\n",
    "df_train['train_label'] = train_label\n",
    "\n",
    "\n",
    "train_label = train_label.values\n",
    "\n",
    "# train_label = to_categorical(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Test Data\n",
    "\n",
    "choose the features: \n",
    "\n",
    "*velocty for pred data is weired\n",
    "\n",
    "Change the time values into float, by dividing into minutes.\n",
    "\n",
    "Finally, store test_data_pred and test_data_eval as NumPy arrays, and normalize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred\n",
    "\n",
    "df_test['time_entry_seconds'] = pd.to_timedelta(df_test['time_entry']).dt.total_seconds()\n",
    "df_test['time_exit_seconds']=pd.to_timedelta(df_test['time_exit']).dt.total_seconds()\n",
    "df_test['time_stayed_seconds']=df_test['time_exit_seconds']-df_test['time_entry_seconds']\n",
    "\n",
    "x_in_city = (df_test['x_entry'] >=3750901.5068) & (df_test['x_entry']<=3770901.5068)\n",
    "y_in_city = (df_test['y_entry'] >= -19268905.6133) & (df_test['y_entry'] <= -19208905.6133)\n",
    "\n",
    "df_test['entry_inside'] = 1*(x_in_city & y_in_city)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide Pred and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pred = df_test[df_test['x_exit'] == \"\"]\n",
    "df_test_eval = df_test[df_test['x_exit'] != \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_pred = df_test_pred.loc[:,['time_stayed_seconds','entry_inside']]\n",
    "test_data_pred = test_data_pred.values\n",
    "\n",
    "test_data_eval = df_test_eval.loc[:,['time_stayed_seconds','entry_inside']]\n",
    "test_data_eval = test_data_eval.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare Test Labels\n",
    "\n",
    "prepare the label for test:\n",
    "\n",
    "x_exit and y_exit values from df_test_eval (not pred). 0 or 1 in train_label NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Godwithus/anaconda3/envs/tf_env/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>trajectory_id</th>\n",
       "      <th>time_entry</th>\n",
       "      <th>time_exit</th>\n",
       "      <th>vmax</th>\n",
       "      <th>vmin</th>\n",
       "      <th>vmean</th>\n",
       "      <th>x_entry</th>\n",
       "      <th>y_entry</th>\n",
       "      <th>x_exit</th>\n",
       "      <th>y_exit</th>\n",
       "      <th>time_entry_seconds</th>\n",
       "      <th>time_exit_seconds</th>\n",
       "      <th>time_stayed_seconds</th>\n",
       "      <th>entry_inside</th>\n",
       "      <th>test_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00032f51796fd5437b238e3a9823d13d_31</td>\n",
       "      <td>traj_00032f51796fd5437b238e3a9823d13d_31_0</td>\n",
       "      <td>11:43:17</td>\n",
       "      <td>11:50:17</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.773413e+06</td>\n",
       "      <td>-1.909828e+07</td>\n",
       "      <td>3.77311e+06</td>\n",
       "      <td>-1.91451e+07</td>\n",
       "      <td>42197.0</td>\n",
       "      <td>42617.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00032f51796fd5437b238e3a9823d13d_31</td>\n",
       "      <td>traj_00032f51796fd5437b238e3a9823d13d_31_2</td>\n",
       "      <td>12:21:37</td>\n",
       "      <td>12:21:37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.773199e+06</td>\n",
       "      <td>-1.914354e+07</td>\n",
       "      <td>3.7732e+06</td>\n",
       "      <td>-1.91435e+07</td>\n",
       "      <td>44497.0</td>\n",
       "      <td>44497.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00032f51796fd5437b238e3a9823d13d_31</td>\n",
       "      <td>traj_00032f51796fd5437b238e3a9823d13d_31_3</td>\n",
       "      <td>12:34:27</td>\n",
       "      <td>13:14:11</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.763760e+06</td>\n",
       "      <td>-1.921342e+07</td>\n",
       "      <td>3.77176e+06</td>\n",
       "      <td>-1.91109e+07</td>\n",
       "      <td>45267.0</td>\n",
       "      <td>47651.0</td>\n",
       "      <td>2384.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00032f51796fd5437b238e3a9823d13d_31</td>\n",
       "      <td>traj_00032f51796fd5437b238e3a9823d13d_31_4</td>\n",
       "      <td>13:25:33</td>\n",
       "      <td>13:43:13</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.773385e+06</td>\n",
       "      <td>-1.911344e+07</td>\n",
       "      <td>3.77313e+06</td>\n",
       "      <td>-1.91447e+07</td>\n",
       "      <td>48333.0</td>\n",
       "      <td>49393.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>000479418b5561ab694a2870cc04fd43_25</td>\n",
       "      <td>traj_000479418b5561ab694a2870cc04fd43_25_0</td>\n",
       "      <td>08:08:23</td>\n",
       "      <td>08:20:08</td>\n",
       "      <td>17.29</td>\n",
       "      <td>17.29</td>\n",
       "      <td>17.29</td>\n",
       "      <td>3.771380e+06</td>\n",
       "      <td>-1.933274e+07</td>\n",
       "      <td>3.76993e+06</td>\n",
       "      <td>-1.93409e+07</td>\n",
       "      <td>29303.0</td>\n",
       "      <td>30008.0</td>\n",
       "      <td>705.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  hash  \\\n",
       "0  00032f51796fd5437b238e3a9823d13d_31   \n",
       "1  00032f51796fd5437b238e3a9823d13d_31   \n",
       "2  00032f51796fd5437b238e3a9823d13d_31   \n",
       "3  00032f51796fd5437b238e3a9823d13d_31   \n",
       "5  000479418b5561ab694a2870cc04fd43_25   \n",
       "\n",
       "                                trajectory_id time_entry time_exit   vmax  \\\n",
       "0  traj_00032f51796fd5437b238e3a9823d13d_31_0   11:43:17  11:50:17          \n",
       "1  traj_00032f51796fd5437b238e3a9823d13d_31_2   12:21:37  12:21:37      0   \n",
       "2  traj_00032f51796fd5437b238e3a9823d13d_31_3   12:34:27  13:14:11          \n",
       "3  traj_00032f51796fd5437b238e3a9823d13d_31_4   13:25:33  13:43:13          \n",
       "5  traj_000479418b5561ab694a2870cc04fd43_25_0   08:08:23  08:20:08  17.29   \n",
       "\n",
       "    vmin  vmean       x_entry       y_entry       x_exit       y_exit  \\\n",
       "0                3.773413e+06 -1.909828e+07  3.77311e+06 -1.91451e+07   \n",
       "1      0      0  3.773199e+06 -1.914354e+07   3.7732e+06 -1.91435e+07   \n",
       "2                3.763760e+06 -1.921342e+07  3.77176e+06 -1.91109e+07   \n",
       "3                3.773385e+06 -1.911344e+07  3.77313e+06 -1.91447e+07   \n",
       "5  17.29  17.29  3.771380e+06 -1.933274e+07  3.76993e+06 -1.93409e+07   \n",
       "\n",
       "   time_entry_seconds  time_exit_seconds  time_stayed_seconds  entry_inside  \\\n",
       "0             42197.0            42617.0                420.0             0   \n",
       "1             44497.0            44497.0                  0.0             0   \n",
       "2             45267.0            47651.0               2384.0             1   \n",
       "3             48333.0            49393.0               1060.0             0   \n",
       "5             29303.0            30008.0                705.0             0   \n",
       "\n",
       "   test_label  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "5           0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare test label\n",
    "\n",
    "target_x = (df_test_eval['x_exit']>=3750901.5068) & (df_test_eval['x_exit']<=3770901.5068)\n",
    "target_y = (df_test_eval['y_exit']>=-19268905.6133) & (df_test_eval['y_exit']<=-19208905.6133)\n",
    "\n",
    "test_label = 1*(target_x & target_y)\n",
    "\n",
    "df_test_eval['test_label'] = test_label\n",
    "\n",
    "test_label = test_label.values\n",
    "\n",
    "df_test_eval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom F1 loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define Keras NN model\n",
    "\n",
    "binary softmax, but categorical_crossentropy loss. *can improve loss, optimizer, layer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Godwithus/anaconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 814262 samples, validate on 169422 samples\n",
      "WARNING:tensorflow:From /Users/Godwithus/anaconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/4\n",
      "813920/814262 [============================>.] - ETA: 0s - loss: 2.8688 - acc: 0.8197— val_f1: 0.882603 — val_precision: 0.943172 — val_recall 0.829344\n",
      "814262/814262 [==============================] - 89s 109us/sample - loss: 2.8682 - acc: 0.8198 - val_loss: 1.0578 - val_acc: 0.9330\n",
      "Epoch 2/4\n",
      "336096/814262 [===========>..................] - ETA: 47s - loss: 1.0677 - acc: 0.9334"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-93dd39fa96b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m history = model.fit(train_data, train_label, epochs=4, \\\n\u001b[0;32m---> 18\u001b[0;31m                     validation_data=(test_data_eval, test_label), callbacks=[reach_90acc, f1]) #, f1\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/envs/tf_env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train_data = train_data.reshape(814262, 7,1)\n",
    "#define model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#complile the model\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "#fit the model\n",
    "f1 = F1((test_data_eval, test_label))\n",
    "history = model.fit(train_data, train_label, epochs=4, \\\n",
    "                    validation_data=(test_data_eval, test_label), callbacks=[reach_90acc, f1]) #, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the Model\n",
    "\n",
    "print the summary and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data_eval = test_data_eval.reshape(169422, 7, 1)\n",
    "\n",
    "#evaluate the accuracy of the model\n",
    "model.summary()\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_data_eval, test_label)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the model's Learning Curve\n",
    "\n",
    "https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for acc\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the Data\n",
    "\n",
    "Predict the test_data_pred and if the p(xi) is over 0.5, save it as 1, otherwise 0. Predictions is the NumPy array saving the result. Formulate pd.DataFrame from df_testPred['trajectory_id'] and predictions ('target') so that the output DataFrame is in ['id', 'target'] format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data_pred = test_data_pred.reshape(33515, 7, 1)\n",
    "\n",
    "#predict and handle output\n",
    "predictions = model.predict(test_data_pred)\n",
    "\n",
    "print(predictions)\n",
    "predictions = (predictions >= 0.5) *1\n",
    "\n",
    "id = pd.DataFrame(df_test_pred['trajectory_id'])\n",
    "\n",
    "target = pd.DataFrame(predictions)\n",
    "# target.columns = ['zeros','target']\n",
    "# target = target['target']\n",
    "target.columns = ['target']\n",
    "\n",
    "output = pd.concat([id.reset_index(drop=True),target.reset_index(drop=True)], axis=1)\n",
    "output.columns = ['id', 'target']\n",
    "output.to_csv(\"/Users/Godwithus/Desktop/EY/try_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debugging\n",
    "print(\"test_data_pred\", test_data_pred.shape)\n",
    "print(\"predictions\", predictions.shape)\n",
    "print(\"df_test_pred\", df_test_pred.shape)\n",
    "print(\"id\", id.shape)\n",
    "print(\"target\", target.shape)\n",
    "print(\"output\", output.shape)\n",
    "\n",
    "print(output)\n",
    "\n",
    "print(target.sum()/np.size(target, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
